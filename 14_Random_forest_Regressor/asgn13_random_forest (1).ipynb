{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e87b6a3-99a0-47d4-9765-71f8eef6bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd027fe-b39c-4d2d-98e8-7e06f6131a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'/home/infinitex/Desktop/JupiterNotebook/Asgn 13 RandomForest/Wine - Wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d428a59-7df6-4cb1-894d-09a9024a186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.236815</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>-0.328222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic_Acid</th>\n",
       "      <td>0.094397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>0.437776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>0.211545</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>-0.049643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>0.517859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>0.270798</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>-0.209179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Phenols</th>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>-0.719163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>0.236815</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.537900</td>\n",
       "      <td>0.652692</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>0.494193</td>\n",
       "      <td>-0.847498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>-0.537900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>0.489109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>0.136698</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>0.652692</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>-0.499130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color_Intensity</th>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.265668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>-0.071747</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>-0.617369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280</th>\n",
       "      <td>0.072343</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>-0.788230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>0.643720</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>0.494193</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.633717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_Segment</th>\n",
       "      <td>-0.328222</td>\n",
       "      <td>0.437776</td>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.209179</td>\n",
       "      <td>-0.719163</td>\n",
       "      <td>-0.847498</td>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.788230</td>\n",
       "      <td>-0.633717</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Alcohol  Malic_Acid       Ash  Ash_Alcanity  Magnesium  \\\n",
       "Alcohol               1.000000    0.094397  0.211545     -0.310235   0.270798   \n",
       "Malic_Acid            0.094397    1.000000  0.164045      0.288500  -0.054575   \n",
       "Ash                   0.211545    0.164045  1.000000      0.443367   0.286587   \n",
       "Ash_Alcanity         -0.310235    0.288500  0.443367      1.000000  -0.083333   \n",
       "Magnesium             0.270798   -0.054575  0.286587     -0.083333   1.000000   \n",
       "Total_Phenols         0.289101   -0.335167  0.128980     -0.321113   0.214401   \n",
       "Flavanoids            0.236815   -0.411007  0.115077     -0.351370   0.195784   \n",
       "Nonflavanoid_Phenols -0.155929    0.292977  0.186230      0.361922  -0.256294   \n",
       "Proanthocyanins       0.136698   -0.220746  0.009652     -0.197327   0.236441   \n",
       "Color_Intensity       0.546364    0.248985  0.258887      0.018732   0.199950   \n",
       "Hue                  -0.071747   -0.561296 -0.074667     -0.273955   0.055398   \n",
       "OD280                 0.072343   -0.368710  0.003911     -0.276769   0.066004   \n",
       "Proline               0.643720   -0.192011  0.223626     -0.440597   0.393351   \n",
       "Customer_Segment     -0.328222    0.437776 -0.049643      0.517859  -0.209179   \n",
       "\n",
       "                      Total_Phenols  Flavanoids  Nonflavanoid_Phenols  \\\n",
       "Alcohol                    0.289101    0.236815             -0.155929   \n",
       "Malic_Acid                -0.335167   -0.411007              0.292977   \n",
       "Ash                        0.128980    0.115077              0.186230   \n",
       "Ash_Alcanity              -0.321113   -0.351370              0.361922   \n",
       "Magnesium                  0.214401    0.195784             -0.256294   \n",
       "Total_Phenols              1.000000    0.864564             -0.449935   \n",
       "Flavanoids                 0.864564    1.000000             -0.537900   \n",
       "Nonflavanoid_Phenols      -0.449935   -0.537900              1.000000   \n",
       "Proanthocyanins            0.612413    0.652692             -0.365845   \n",
       "Color_Intensity           -0.055136   -0.172379              0.139057   \n",
       "Hue                        0.433681    0.543479             -0.262640   \n",
       "OD280                      0.699949    0.787194             -0.503270   \n",
       "Proline                    0.498115    0.494193             -0.311385   \n",
       "Customer_Segment          -0.719163   -0.847498              0.489109   \n",
       "\n",
       "                      Proanthocyanins  Color_Intensity       Hue     OD280  \\\n",
       "Alcohol                      0.136698         0.546364 -0.071747  0.072343   \n",
       "Malic_Acid                  -0.220746         0.248985 -0.561296 -0.368710   \n",
       "Ash                          0.009652         0.258887 -0.074667  0.003911   \n",
       "Ash_Alcanity                -0.197327         0.018732 -0.273955 -0.276769   \n",
       "Magnesium                    0.236441         0.199950  0.055398  0.066004   \n",
       "Total_Phenols                0.612413        -0.055136  0.433681  0.699949   \n",
       "Flavanoids                   0.652692        -0.172379  0.543479  0.787194   \n",
       "Nonflavanoid_Phenols        -0.365845         0.139057 -0.262640 -0.503270   \n",
       "Proanthocyanins              1.000000        -0.025250  0.295544  0.519067   \n",
       "Color_Intensity             -0.025250         1.000000 -0.521813 -0.428815   \n",
       "Hue                          0.295544        -0.521813  1.000000  0.565468   \n",
       "OD280                        0.519067        -0.428815  0.565468  1.000000   \n",
       "Proline                      0.330417         0.316100  0.236183  0.312761   \n",
       "Customer_Segment            -0.499130         0.265668 -0.617369 -0.788230   \n",
       "\n",
       "                       Proline  Customer_Segment  \n",
       "Alcohol               0.643720         -0.328222  \n",
       "Malic_Acid           -0.192011          0.437776  \n",
       "Ash                   0.223626         -0.049643  \n",
       "Ash_Alcanity         -0.440597          0.517859  \n",
       "Magnesium             0.393351         -0.209179  \n",
       "Total_Phenols         0.498115         -0.719163  \n",
       "Flavanoids            0.494193         -0.847498  \n",
       "Nonflavanoid_Phenols -0.311385          0.489109  \n",
       "Proanthocyanins       0.330417         -0.499130  \n",
       "Color_Intensity       0.316100          0.265668  \n",
       "Hue                   0.236183         -0.617369  \n",
       "OD280                 0.312761         -0.788230  \n",
       "Proline               1.000000         -0.633717  \n",
       "Customer_Segment     -0.633717          1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display correlation matrix\n",
    "correlation_matrix =df.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e47ac6b9-8fb6-494e-9217-d11b48c8b8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.8 , 3.06],\n",
       "        [2.65, 2.76],\n",
       "        [2.8 , 3.24],\n",
       "        [3.85, 3.49],\n",
       "        [2.8 , 2.69],\n",
       "        [3.27, 3.39],\n",
       "        [2.5 , 2.52],\n",
       "        [2.6 , 2.51],\n",
       "        [2.8 , 2.98],\n",
       "        [2.98, 3.15],\n",
       "        [2.95, 3.32],\n",
       "        [2.2 , 2.43],\n",
       "        [2.6 , 2.76],\n",
       "        [3.1 , 3.69],\n",
       "        [3.3 , 3.64],\n",
       "        [2.85, 2.91],\n",
       "        [2.8 , 3.14],\n",
       "        [2.95, 3.4 ],\n",
       "        [3.3 , 3.93],\n",
       "        [2.7 , 3.03],\n",
       "        [3.  , 3.17],\n",
       "        [2.41, 2.41],\n",
       "        [2.61, 2.88],\n",
       "        [2.48, 2.37],\n",
       "        [2.53, 2.61],\n",
       "        [2.63, 2.68],\n",
       "        [2.85, 2.94],\n",
       "        [2.4 , 2.19],\n",
       "        [2.95, 2.97],\n",
       "        [2.65, 2.33],\n",
       "        [3.  , 3.25],\n",
       "        [2.86, 3.19],\n",
       "        [2.42, 2.69],\n",
       "        [2.95, 2.74],\n",
       "        [2.35, 2.53],\n",
       "        [2.7 , 2.98],\n",
       "        [2.6 , 2.68],\n",
       "        [2.45, 2.43],\n",
       "        [2.4 , 2.64],\n",
       "        [3.  , 3.04],\n",
       "        [3.15, 3.29],\n",
       "        [2.45, 2.68],\n",
       "        [3.25, 3.56],\n",
       "        [2.64, 2.63],\n",
       "        [3.  , 3.  ],\n",
       "        [2.85, 2.65],\n",
       "        [3.25, 3.17],\n",
       "        [3.1 , 3.39],\n",
       "        [2.75, 2.92],\n",
       "        [2.88, 3.54],\n",
       "        [2.72, 3.27],\n",
       "        [2.45, 2.99],\n",
       "        [3.88, 3.74],\n",
       "        [3.  , 2.79],\n",
       "        [2.6 , 2.9 ],\n",
       "        [2.96, 2.78],\n",
       "        [3.2 , 3.  ],\n",
       "        [3.  , 3.23],\n",
       "        [3.4 , 3.67],\n",
       "        [1.98, 0.57],\n",
       "        [2.05, 1.09],\n",
       "        [2.02, 1.41],\n",
       "        [2.1 , 1.79],\n",
       "        [3.5 , 3.1 ],\n",
       "        [1.89, 1.75],\n",
       "        [2.42, 2.65],\n",
       "        [2.98, 3.18],\n",
       "        [2.11, 2.  ],\n",
       "        [2.53, 1.3 ],\n",
       "        [1.85, 1.28],\n",
       "        [1.1 , 1.02],\n",
       "        [2.95, 2.86],\n",
       "        [1.88, 1.84],\n",
       "        [3.3 , 2.89],\n",
       "        [3.38, 2.14],\n",
       "        [1.61, 1.57],\n",
       "        [1.95, 2.03],\n",
       "        [1.72, 1.32],\n",
       "        [1.9 , 1.85],\n",
       "        [2.83, 2.55],\n",
       "        [2.42, 2.26],\n",
       "        [2.2 , 2.53],\n",
       "        [2.  , 1.58],\n",
       "        [1.65, 1.59],\n",
       "        [2.2 , 2.21],\n",
       "        [2.2 , 1.94],\n",
       "        [1.78, 1.69],\n",
       "        [1.92, 1.61],\n",
       "        [1.95, 1.69],\n",
       "        [2.2 , 1.59],\n",
       "        [1.6 , 1.5 ],\n",
       "        [1.45, 1.25],\n",
       "        [1.38, 1.46],\n",
       "        [2.45, 2.25],\n",
       "        [3.02, 2.26],\n",
       "        [2.5 , 2.27],\n",
       "        [1.6 , 0.99],\n",
       "        [2.55, 2.5 ],\n",
       "        [3.52, 3.75],\n",
       "        [2.85, 2.99],\n",
       "        [2.23, 2.17],\n",
       "        [1.45, 1.36],\n",
       "        [2.56, 2.11],\n",
       "        [2.5 , 1.64],\n",
       "        [2.2 , 1.92],\n",
       "        [1.68, 1.84],\n",
       "        [1.65, 2.03],\n",
       "        [1.38, 1.76],\n",
       "        [2.36, 2.04],\n",
       "        [2.74, 2.92],\n",
       "        [3.18, 2.58],\n",
       "        [2.55, 2.27],\n",
       "        [1.75, 2.03],\n",
       "        [2.48, 2.01],\n",
       "        [2.56, 2.29],\n",
       "        [2.46, 2.17],\n",
       "        [1.98, 1.6 ],\n",
       "        [2.  , 2.09],\n",
       "        [1.63, 1.25],\n",
       "        [2.  , 1.64],\n",
       "        [2.9 , 2.79],\n",
       "        [3.18, 5.08],\n",
       "        [2.2 , 2.13],\n",
       "        [2.62, 2.65],\n",
       "        [2.86, 3.03],\n",
       "        [2.6 , 2.65],\n",
       "        [2.74, 3.15],\n",
       "        [2.13, 2.24],\n",
       "        [2.22, 2.45],\n",
       "        [2.1 , 1.75],\n",
       "        [1.51, 1.25],\n",
       "        [1.3 , 1.22],\n",
       "        [1.15, 1.09],\n",
       "        [1.7 , 1.2 ],\n",
       "        [2.  , 0.58],\n",
       "        [1.62, 0.66],\n",
       "        [1.38, 0.47],\n",
       "        [1.79, 0.6 ],\n",
       "        [1.62, 0.48],\n",
       "        [2.32, 0.6 ],\n",
       "        [1.54, 0.5 ],\n",
       "        [1.4 , 0.5 ],\n",
       "        [1.55, 0.52],\n",
       "        [2.  , 0.8 ],\n",
       "        [1.38, 0.78],\n",
       "        [1.5 , 0.55],\n",
       "        [0.98, 0.34],\n",
       "        [1.7 , 0.65],\n",
       "        [1.93, 0.76],\n",
       "        [1.41, 1.39],\n",
       "        [1.4 , 1.57],\n",
       "        [1.48, 1.36],\n",
       "        [2.2 , 1.28],\n",
       "        [1.8 , 0.83],\n",
       "        [1.48, 0.58],\n",
       "        [1.74, 0.63],\n",
       "        [1.8 , 0.83],\n",
       "        [1.9 , 0.58],\n",
       "        [2.8 , 1.31],\n",
       "        [2.6 , 1.1 ],\n",
       "        [2.3 , 0.92],\n",
       "        [1.83, 0.56],\n",
       "        [1.65, 0.6 ],\n",
       "        [1.39, 0.7 ],\n",
       "        [1.35, 0.68],\n",
       "        [1.28, 0.47],\n",
       "        [1.7 , 0.92],\n",
       "        [1.48, 0.66],\n",
       "        [1.55, 0.84],\n",
       "        [1.98, 0.96],\n",
       "        [1.25, 0.49],\n",
       "        [1.39, 0.51],\n",
       "        [1.68, 0.7 ],\n",
       "        [1.68, 0.61],\n",
       "        [1.8 , 0.75],\n",
       "        [1.59, 0.69],\n",
       "        [1.65, 0.68],\n",
       "        [2.05, 0.76]]),\n",
       " array([[3.92],\n",
       "        [3.4 ],\n",
       "        [3.17],\n",
       "        [3.45],\n",
       "        [2.93],\n",
       "        [2.85],\n",
       "        [3.58],\n",
       "        [3.58],\n",
       "        [2.85],\n",
       "        [3.55],\n",
       "        [3.17],\n",
       "        [2.82],\n",
       "        [2.9 ],\n",
       "        [2.73],\n",
       "        [3.  ],\n",
       "        [2.88],\n",
       "        [2.65],\n",
       "        [2.57],\n",
       "        [2.82],\n",
       "        [3.36],\n",
       "        [3.71],\n",
       "        [3.52],\n",
       "        [4.  ],\n",
       "        [3.63],\n",
       "        [3.82],\n",
       "        [3.2 ],\n",
       "        [3.22],\n",
       "        [2.77],\n",
       "        [3.4 ],\n",
       "        [3.59],\n",
       "        [2.71],\n",
       "        [2.88],\n",
       "        [2.87],\n",
       "        [3.  ],\n",
       "        [2.87],\n",
       "        [3.47],\n",
       "        [2.78],\n",
       "        [2.51],\n",
       "        [2.69],\n",
       "        [3.53],\n",
       "        [3.38],\n",
       "        [3.  ],\n",
       "        [3.56],\n",
       "        [3.  ],\n",
       "        [3.35],\n",
       "        [3.33],\n",
       "        [3.44],\n",
       "        [3.33],\n",
       "        [2.75],\n",
       "        [3.1 ],\n",
       "        [2.91],\n",
       "        [3.37],\n",
       "        [3.26],\n",
       "        [2.93],\n",
       "        [3.2 ],\n",
       "        [3.03],\n",
       "        [3.31],\n",
       "        [2.84],\n",
       "        [2.87],\n",
       "        [1.82],\n",
       "        [1.67],\n",
       "        [1.59],\n",
       "        [2.46],\n",
       "        [2.87],\n",
       "        [2.23],\n",
       "        [2.3 ],\n",
       "        [3.18],\n",
       "        [3.48],\n",
       "        [1.93],\n",
       "        [3.07],\n",
       "        [1.82],\n",
       "        [3.16],\n",
       "        [2.78],\n",
       "        [3.5 ],\n",
       "        [3.13],\n",
       "        [2.14],\n",
       "        [2.48],\n",
       "        [2.52],\n",
       "        [2.31],\n",
       "        [3.13],\n",
       "        [3.12],\n",
       "        [3.14],\n",
       "        [2.72],\n",
       "        [2.01],\n",
       "        [3.08],\n",
       "        [3.16],\n",
       "        [2.26],\n",
       "        [3.21],\n",
       "        [2.75],\n",
       "        [3.21],\n",
       "        [2.27],\n",
       "        [2.65],\n",
       "        [2.06],\n",
       "        [3.3 ],\n",
       "        [2.96],\n",
       "        [2.63],\n",
       "        [2.26],\n",
       "        [2.74],\n",
       "        [2.77],\n",
       "        [2.83],\n",
       "        [2.96],\n",
       "        [2.77],\n",
       "        [3.38],\n",
       "        [2.44],\n",
       "        [3.57],\n",
       "        [3.3 ],\n",
       "        [3.17],\n",
       "        [2.42],\n",
       "        [3.02],\n",
       "        [3.26],\n",
       "        [2.81],\n",
       "        [2.78],\n",
       "        [2.5 ],\n",
       "        [2.31],\n",
       "        [3.19],\n",
       "        [2.87],\n",
       "        [3.33],\n",
       "        [2.96],\n",
       "        [2.12],\n",
       "        [3.05],\n",
       "        [3.39],\n",
       "        [3.69],\n",
       "        [3.12],\n",
       "        [3.1 ],\n",
       "        [3.64],\n",
       "        [3.28],\n",
       "        [2.84],\n",
       "        [2.44],\n",
       "        [2.78],\n",
       "        [2.57],\n",
       "        [1.29],\n",
       "        [1.42],\n",
       "        [1.36],\n",
       "        [1.29],\n",
       "        [1.51],\n",
       "        [1.58],\n",
       "        [1.27],\n",
       "        [1.69],\n",
       "        [1.82],\n",
       "        [2.15],\n",
       "        [2.31],\n",
       "        [2.47],\n",
       "        [2.06],\n",
       "        [2.05],\n",
       "        [2.  ],\n",
       "        [1.68],\n",
       "        [1.33],\n",
       "        [1.86],\n",
       "        [1.62],\n",
       "        [1.33],\n",
       "        [1.3 ],\n",
       "        [1.47],\n",
       "        [1.33],\n",
       "        [1.51],\n",
       "        [1.55],\n",
       "        [1.48],\n",
       "        [1.64],\n",
       "        [1.73],\n",
       "        [1.96],\n",
       "        [1.78],\n",
       "        [1.58],\n",
       "        [1.82],\n",
       "        [2.11],\n",
       "        [1.75],\n",
       "        [1.68],\n",
       "        [1.75],\n",
       "        [1.56],\n",
       "        [1.75],\n",
       "        [1.8 ],\n",
       "        [1.92],\n",
       "        [1.83],\n",
       "        [1.63],\n",
       "        [1.71],\n",
       "        [1.74],\n",
       "        [1.56],\n",
       "        [1.56],\n",
       "        [1.62],\n",
       "        [1.6 ]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iloc\n",
    "X = df.iloc[:, 5:7].values\n",
    "Y= df.iloc[:,11:12].values\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec753237-d1f1-4715-b0aa-df0797176a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infinitex/.local/lib/python3.9/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(min_samples_leaf=3, n_estimators=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(min_samples_leaf=3, n_estimators=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=3, n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#raining the Random Forest Regression model on the whole dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0,min_samples_leaf=3)\n",
    "regressor.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e190e237-e67c-4dca-be7c-351b8478c270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Estimators (Trees): 10\n",
      "Feature Importances: [0.09338709 0.90661291]\n",
      "Max Depth of Trees: [8, 9, 7, 9, 10, 9, 9, 9, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "#Description of random forest regression model\n",
    "print(\"Number of Estimators (Trees):\", regressor.n_estimators)\n",
    "print(\"Feature Importances:\", regressor.feature_importances_)\n",
    "print(\"Max Depth of Trees:\", [estimator.tree_.max_depth for estimator in regressor.estimators_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a2c507-9aff-44d3-a203-0256b6ea6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for Random Forest regression model\n",
    "#Hyperparameters of a Random Forest\n",
    "#max_depth: The maximum depth of the tree - meaning the longest path between the root node and the leaf node. \n",
    "#max_leaf_nodes: This is the maximum number of leaf nodes a decision tree can have.. \n",
    "#n_estimators: This is the number of trees in the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdecdc11-b60b-4d61-96f5-c87a9aa3ace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infinitex/.local/lib/python3.9/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(min_samples_leaf=5, n_estimators=15, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(min_samples_leaf=5, n_estimators=15, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=5, n_estimators=15, random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators = 15, random_state = 0,min_samples_leaf=5)\n",
    "regressor.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b7b667-3d23-4d10-ba77-deb8e3cfaa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infinitex/.local/lib/python3.9/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(min_samples_leaf=8, n_estimators=5, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(min_samples_leaf=8, n_estimators=5, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=8, n_estimators=5, random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators = 5, random_state = 0,min_samples_leaf=8)\n",
    "regressor.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8f581-ac8c-4e64-b79a-65689f2468a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
